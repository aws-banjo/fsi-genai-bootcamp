{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy fine-tuned model\n",
    "Now that we have fine-tuned the model, we can deploy it to a SageMaker endpoint. There are numerous deployment [options](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html) in SageMaker including RealTime, Serverless, Asynchronous, and Batch Transform. In this notebook, we will deploy the model as a RealTime endpoint. \n",
    "There are also numerous options for deploying LLMs for RealTime inference including:\n",
    "- Single model or multi-model endpoints\n",
    "- Instance Types (GPU, Inferentia2)\n",
    "- Various inference frameworks such as Large Model Inference, Text Generation Inference, TorchServe, and TensorRT LLM\n",
    "We'll use the Large Model Inference (LMI) container to deploy the LLM. \n",
    "\n",
    "Refer to the blog post [here](https://aws.amazon.com/blogs/machine-learning/boost-inference-performance-for-mixtral-and-llama-2-models-with-new-amazon-sagemaker-containers/) for detailed recommendations for configuring various model architectures for optimal performance on thr LMI container. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating base environment\n",
      "Base environment validated successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #4cc9f0; text-decoration-color: #4cc9f0; font-weight: bold\">Validating lab environment from requirements.txt</span> âœ¨\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;76;201;240mValidating lab environment from requirements.txt\u001b[0m âœ¨\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #e85d04; text-decoration-color: #e85d04; font-weight: bold; text-decoration: underline\">ENVIRONMENT STATUS</span>\n",
       "âœ… <span style=\"color: #008000; text-decoration-color: #008000\"> beautifulsoup4 is installed</span>\n",
       "âœ… <span style=\"color: #008000; text-decoration-color: #008000\"> lxml is installed</span>\n",
       "âœ… <span style=\"color: #008000; text-decoration-color: #008000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">langchain</span><span style=\"color: #008000; text-decoration-color: #008000\">==</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.3</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span><span style=\"color: #008000; text-decoration-color: #008000\"> is installed</span>\n",
       "âœ… <span style=\"color: #008000; text-decoration-color: #008000\"> langchain-</span><span style=\"color: #008000; text-decoration-color: #008000\">aws</span><span style=\"color: #008000; text-decoration-color: #008000\">==</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.2</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">11</span><span style=\"color: #008000; text-decoration-color: #008000\"> is installed</span>\n",
       "âœ… <span style=\"color: #008000; text-decoration-color: #008000\"> faiss-</span><span style=\"color: #008000; text-decoration-color: #008000\">cpu</span><span style=\"color: #008000; text-decoration-color: #008000\">==</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.8</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span><span style=\"color: #008000; text-decoration-color: #008000\"> is installed</span>\n",
       "âœ… <span style=\"color: #008000; text-decoration-color: #008000\"> rank-bm25 is installed</span>\n",
       "âœ… <span style=\"color: #008000; text-decoration-color: #008000\"> sagemaker&gt;=</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">2.239</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span><span style=\"color: #008000; text-decoration-color: #008000\"> is installed</span>\n",
       "âœ… <span style=\"color: #008000; text-decoration-color: #008000\"> seaborn is installed</span>\n",
       "âœ… <span style=\"color: #008000; text-decoration-color: #008000\"> sagemaker-mlflow is installed</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;4;38;2;232;93;4mENVIRONMENT STATUS\u001b[0m\n",
       "âœ… \u001b[32m beautifulsoup4 is installed\u001b[0m\n",
       "âœ… \u001b[32m lxml is installed\u001b[0m\n",
       "âœ… \u001b[32m \u001b[0m\u001b[32mlangchain\u001b[0m\u001b[32m==\u001b[0m\u001b[1;32m0.3\u001b[0m\u001b[32m.\u001b[0m\u001b[1;32m5\u001b[0m\u001b[32m is installed\u001b[0m\n",
       "âœ… \u001b[32m langchain-\u001b[0m\u001b[32maws\u001b[0m\u001b[32m==\u001b[0m\u001b[1;32m0.2\u001b[0m\u001b[32m.\u001b[0m\u001b[1;32m11\u001b[0m\u001b[32m is installed\u001b[0m\n",
       "âœ… \u001b[32m faiss-\u001b[0m\u001b[32mcpu\u001b[0m\u001b[32m==\u001b[0m\u001b[1;32m1.8\u001b[0m\u001b[32m.\u001b[0m\u001b[1;32m0\u001b[0m\u001b[32m is installed\u001b[0m\n",
       "âœ… \u001b[32m rank-bm25 is installed\u001b[0m\n",
       "âœ… \u001b[32m sagemaker>=\u001b[0m\u001b[1;32m2.239\u001b[0m\u001b[32m.\u001b[0m\u001b[1;32m0\u001b[0m\u001b[32m is installed\u001b[0m\n",
       "âœ… \u001b[32m seaborn is installed\u001b[0m\n",
       "âœ… \u001b[32m sagemaker-mlflow is installed\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #a7c957; text-decoration-color: #a7c957\">All required libraries are installed.ðŸŽ‰</span>\n",
       "<span style=\"color: #a7c957; text-decoration-color: #a7c957\">You may proceed with the lab! ðŸš€</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;167;201;87mAll required libraries are installed.ðŸŽ‰\u001b[0m\n",
       "\u001b[38;2;167;201;87mYou may proceed with the lab! ðŸš€\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "module_path = \"../..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils.environment_validation import validate_environment, validate_model_access\n",
    "validate_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from pathlib import Path\n",
    "from sagemaker.djl_inference.model import DJLModel\n",
    "from sagemaker import serializers, deserializers\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "bucket = sess.default_bucket()  # default bucket name\n",
    "account_id = sess.account_id() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to upload our merged model to S3\n",
    "local_model_path = \"merged_model\"\n",
    "s3_model_path = f\"s3://{bucket}/banking-regulations-model\"\n",
    "!aws s3 sync {local_model_path} {s3_model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/08/25 23:38:06] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Ignoring unnecessary instance type: <span style=\"color: #e100e1; text-decoration-color: #e100e1; font-style: italic\">None</span>.                            <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py#528\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">528</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/08/25 23:38:06]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Ignoring unnecessary instance type: \u001b[3;38;2;225;0;225mNone\u001b[0m.                            \u001b]8;id=474874;file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=626882;file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py#528\u001b\\\u001b[2m528\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define inference environment for LLM\n",
    "# for more details see documentation here https://docs.djl.ai/master/docs/serving/serving/docs/lmi/deployment_guide/configurations.html\n",
    "llm_env = {\n",
    "    \"TENSOR_PARALLEL_DEGREE\": \"1\",  # use 1 GPUs\n",
    "    \"OPTION_ROLLING_BATCH\": \"vllm\", # use VLLM rolling batch\n",
    "    \"OPTION_MAX_ROLLING_BATCH_SIZE\": \"32\", # max rolling batch size (controls the concurrency)\n",
    "    \"OPTION_DTYPE\": \"fp16\", # load weights in fp16\n",
    "    \"OPTION_MAX_MODEL_LEN\": \"16384\", # max context length in tokens for the model\n",
    "    \"OPTION_TRUST_REMOTE_CODE\": \"true\", # trust remote code\n",
    "    \"OPTION_GPU_MEMORY_UTILIZATION\": \"0.95\", # use 95% of GPU memory\n",
    "}\n",
    "\n",
    "# create DJLModel object for LLM\n",
    "# see here for LMI version updates https://github.com/aws/deep-learning-containers/blob/master/available_images.md#large-model-inference-containers \n",
    "sm_llm_model = DJLModel(\n",
    "    model_id=s3_model_path,\n",
    "    djl_version=\"0.30.0\",\n",
    "    djl_framework=\"djl-lmi\",\n",
    "    role=role,\n",
    "    env=llm_env,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/08/25 23:38:07] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: djl-inference-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-02-08-23-38-07-501        <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/08/25 23:38:07]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: djl-inference-\u001b[1;36m2025\u001b[0m-02-08-23-38-07-501        \u001b]8;id=974738;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=837656;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/08/25 23:38:08] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name bank-new-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-02-08-23-38-07-500    <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#5889\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5889</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/08/25 23:38:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name bank-new-\u001b[1;36m2025\u001b[0m-02-08-23-38-07-500    \u001b]8;id=728717;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=224930;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#5889\u001b\\\u001b[2m5889\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name bank-new-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-02-08-23-38-07-500           <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#4711\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4711</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name bank-new-\u001b[1;36m2025\u001b[0m-02-08-23-38-07-500           \u001b]8;id=388736;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=815733;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#4711\u001b\\\u001b[2m4711\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------!"
     ]
    }
   ],
   "source": [
    "instance_type = \"ml.g5.xlarge\"\n",
    "endpoint_name = sagemaker.utils.name_from_base(f\"bank-new\")\n",
    "\n",
    "predictor = sm_llm_model.deploy(initial_instance_count=1,\n",
    "             instance_type=instance_type,\n",
    "             endpoint_name=endpoint_name,\n",
    "             serializer=serializers.JSONSerializer(),\n",
    "             deserializer=deserializers.JSONDeserializer(),\n",
    "             container_startup_health_check_timeout=1800\n",
    "                                \n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the endpoint with an example question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test data\n",
    "\n",
    "import json\n",
    "test_data = []\n",
    "with open(\"data/prepared_data/prepared_data_test.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        test_data.append(json.loads(line))\n",
    "    \n",
    "\n",
    "inference_template = \"[INST] You are a Banking Regulations expert.\\nGiven this context\\nCONTEXT\\n{context}\\n Answer this question\\nQuestion: {question} [/INST]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke the endpoint with a sample question\n",
    "idx = 125\n",
    "context = test_data[idx][\"context\"]\n",
    "question = test_data[idx][\"question\"]\n",
    "answer = test_data[idx][\"answer\"]\n",
    "\n",
    "prompt = inference_template.format(context=context, question=question)\n",
    "\n",
    "response = predictor.predict(\n",
    "    {\"inputs\": prompt, \"parameters\": {\"max_new_tokens\":256, \"do_sample\":False, \"temperature\":0}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the impact of co-branding in the marketing of private education loans, and what disclosure is required to avoid implying endorsement by the covered educational institution?\n",
      "\n",
      "Generated Answer:   Co-branding in the marketing of private education loans can imply endorsement by the covered educational institution, which is prohibited unless the marketing includes a clear and conspicuous disclosure that the covered educational institution does not endorse the creditor's loans and that the creditor is not affiliated with the covered educational institution (Â§ 226.48(a)(1)). \n",
      "\n",
      "Ground Truth Answer:  Co-branding in the marketing of private education loans implies endorsement by the covered educational institution. To avoid implying endorsement, the creditor's marketing must include a clear and conspicuous disclosure that is equally prominent and closely proximate to the reference to the covered educational institution, stating that the covered educational institution does not endorse the creditor's loans and that the creditor is not affiliated with the covered educational institution - Â§ 226.48(a)(2).\n"
     ]
    }
   ],
   "source": [
    "print(\"Question: \", question)\n",
    "print(\"\\nGenerated Answer: \", response[\"generated_text\"])\n",
    "print(\"\\nGround Truth Answer: \", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the endpoint name to a file so we can use it in the next notebook\n",
    "\n",
    "with open(\"endpoint_config.json\", \"w\") as f:\n",
    "    f.write(json.dumps({\"endpoint_name\": endpoint_name}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "In this notebook, we deployed a fine-tuned model to a SageMaker endpoint using the Large Model Inference container. In the next notebook, we will incorporate the endpoint into our RAG pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
